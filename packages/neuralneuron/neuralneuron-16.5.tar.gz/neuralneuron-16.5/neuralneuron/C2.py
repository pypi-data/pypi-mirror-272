def c2():
    print('''

# -*- coding: utf-8 -*-
"""C2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JYAfUBrSuMTaJ5cfSmtCBMcL_YCMCfMu

<h2 style='color:blue' align='center'>Small Image Classification Using Convolutional Neural Network (CNN)</h2>

In this notebook, we will classify small images cifar10 dataset from tensorflow keras datasets. There are total 10 classes as shown below. We will use CNN for classification
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

"""<h4 style="color:purple">Load the dataset</h4>"""

(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()
X_train.shape

X_test.shape

"""Here we see there are 50000 training images and 1000 test images"""

y_train.shape

y_train[:5]

"""y_train is a 2D array, for our classification having 1D array is good enough. so we will convert this to now 1D array"""

y_train = y_train.reshape(-1,)
y_train[:5]

y_test = y_test.reshape(-1,)

classes = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]

"""Let's plot some images to see what they are"""

def plot_sample(X, y, index):
    plt.figure(figsize = (15,2))
    plt.imshow(X[index])
    plt.xlabel(classes[y[index]])

plot_sample(X_train, y_train, 0)

plot_sample(X_train, y_train, 1)

"""Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel can range from 0 to 255. Hence to normalize in 0-->1 range, we need to divide it by 255

<h4 style="color:purple">Normalizing the training data</h4>
"""

X_train = X_train / 255.0
X_test = X_test / 255.0

"""<h4 style="color:purple">Build simple artificial neural network for image classification</h4>"""

ann = models.Sequential([
        layers.Flatten(input_shape=(32,32,3)),
        layers.Dense(3000, activation='relu'),
        layers.Dense(1000, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])

ann.summary()

import pydot
from tensorflow import keras
keras.utils.plot_model(ann)

ann.compile(optimizer='SGD',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

ann.fit(X_train, y_train, epochs=5)

"""**You can see that at the end of 5 epochs, accuracy is at around 49%**"""

from sklearn.metrics import confusion_matrix , classification_report
import numpy as np
y_pred = ann.predict(X_test)
y_pred_classes = [np.argmax(element) for element in y_pred]

print("Classification Report: \n", classification_report(y_test, y_pred_classes))

"""# <h4 style="color:purple">Now let us build a **Convolutional Neural Network** to train our images</h4>"""

cnn = models.Sequential([
    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

cnn.summary()

"""Number of parameters in a CONV layer would be :

((m * n * d)+1)* k), added 1 because of the bias term for each filter. The same expression can be written as follows:

((shape of width of the filter (m) * shape of height of the filter (n)* number of filters in the previous layer (d)+1)*number of filters (k)).

 Where the term “filter” refers to the number of filters in the current layer.


First Conv2D Layer= ((3x3x3) +1) x 32 = 896

---




Second Conv2D Layer = ((3x3x32)+1) x 64= 18496


Dense_3= (2304x64)+64= 147520


Dense_4=(64x10)+10=650






"""

import pydot
from tensorflow import keras
keras.utils.plot_model(cnn)

cnn.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

cnn.fit(X_train, y_train, epochs=5)

"""**With CNN, at the end 5 epochs, accuracy was at around 71% which is a significant improvement over ANN. CNN's are best for image classification and gives superb accuracy. Also computation is much less compared to simple ANN as maxpooling reduces the image dimensions while still preserving the features**"""

cnn.evaluate(X_test,y_test)

y_pred = cnn.predict(X_test)
y_pred[:5]

y_classes = [np.argmax(element) for element in y_pred]
y_classes[:5]

y_test[:5]

plot_sample(X_test, y_test,3)

classes[y_classes[3]]

classes[y_classes[3]]''')
c2()