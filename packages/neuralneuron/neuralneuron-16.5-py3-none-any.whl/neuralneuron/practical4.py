# -*- coding: utf-8 -*-
"""Practical4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OahaaQ_owtmNV2a1l6KLf_Jq8EdHKSmi
"""

import numpy as np
import matplotlib.pyplot as plt

x_train=np.array([[2,4],[4,3],[5,6],[7,5],[9,4],[6,2],[8,3]])
y_train=np.array([1,1,1,1,-1,-1,-1])

weights=np.random.rand(2)
bias=np.random.rand()

learning_rate=0.1
for i in range(100):
  for inputs,label in zip(x_train,y_train):
    summation = np.dot(weights,inputs)+bias
    activation= 1 if summation >= 0 else -1
    weights += learning_rate *(label - activation)*inputs
    bias += learning_rate *(label - activation)

x=np.linspace(0,10,100)
y=-(weights[0]* x + bias)/weights[1]

plt.figure(figsize=(8,6))
plt.scatter(x_train[:,0],x_train[:,1],c=y_train)

plt.plot(x,y,color='red',label='Decision Boundary')
plt.xlabel('Input 1')
plt.ylabel('Input 2')
plt.title('Perceptron Decision Region')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Define input data and labels for AND logic gate
x_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_train = np.array([-1, -1, -1, 1])  # Labels for AND gate

# Initialize weights and bias randomly
weights = np.random.rand(2)
bias = np.random.rand()

# Learning rate
learning_rate = 0.1

# Train the perceptron
for i in range(100):
    for inputs, label in zip(x_train, y_train):
        summation = np.dot(inputs, weights) + bias
        activation = 1 if summation >= 0 else -1
        weights += learning_rate * (label - activation) * inputs
        bias += learning_rate * (label - activation)

# Plot decision boundary
x = np.linspace(0, 5, 100)
y = -(weights[0] * x + bias) / weights[1]

# Plot the training data points
plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train)

# Plot the decision boundary
plt.plot(x, y, color='red',label='Decision Boundary')

# Add labels and legend
plt.xlabel('Input 1')
plt.ylabel('Input 2')
plt.title('Perceptron for AND Logic Gate')
plt.legend()

# Show plot
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Define input data and labels for AND logic gate
x_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_train = np.array([-1, 1, 1, 1])  # Labels for OR gate

# Initialize weights and bias randomly
weights = np.random.rand(2)
bias = np.random.rand()

# Learning rate
learning_rate = 0.1

# Train the perceptron
for i in range(100):
    for inputs, label in zip(x_train, y_train):
        summation = np.dot(inputs, weights) + bias
        activation = 1 if summation >= 0 else -1
        weights += learning_rate * (label - activation) * inputs
        bias += learning_rate * (label - activation)

# Plot decision boundary
x = np.linspace(0, 5, 100)
y = -(weights[0] * x + bias) / weights[1]

# Plot the training data points
plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train)

# Plot the decision boundary
plt.plot(x, y, color='red', label='Decision Boundary')

# Add labels and legend
plt.xlabel('Input 1')
plt.ylabel('Input 2')
plt.title('Perceptron for OR Logic Gate')
plt.legend()

# Show plot
plt.grid(True)
plt.show()