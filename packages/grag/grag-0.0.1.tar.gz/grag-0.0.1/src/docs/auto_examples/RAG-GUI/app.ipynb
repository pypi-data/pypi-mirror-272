{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# RAG-GUI\n\nA cookbook demonstrating how to run a RAG app on streamlit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport sys\nfrom pathlib import Path\n\nimport streamlit as st\nfrom grag.components.multivec_retriever import Retriever\nfrom grag.components.utils import get_config\nfrom grag.components.vectordb.deeplake_client import DeepLakeClient\nfrom grag.rag.basic_rag import BasicRAG\n\nsys.path.insert(1, str(Path(os.getcwd()).parents[1]))\n\nst.set_page_config(\n    page_title=\"GRAG\",\n    menu_items={\n        \"Get Help\": \"https://github.com/arjbingly/Capstone_5\",\n        \"About\": \"This is a simple GUI for GRAG\",\n    },\n)\n\n\ndef spinner(text):\n    \"\"\"Decorator that displays a loading spinner with a custom text message during the execution of a function.\n\n    This decorator wraps any function to show a spinner using Streamlit's st.spinner during the function call,\n    indicating that an operation is in progress. The spinner is displayed with a user-defined text message.\n\n    Args:\n        text (str): The message to display next to the spinner.\n\n    Returns:\n        function: A decorator that takes a function and wraps it in a spinner context.\n    \"\"\"\n\n    def _spinner(func):\n        \"\"\"A decorator function that takes another function and wraps it to show a spinner during its execution.\n\n        Args:\n            func (function): The function to wrap.\n\n        Returns:\n            function: The wrapped function with a spinner displayed during its execution.\n        \"\"\"\n\n        def wrapper_func(*args, **kwargs):\n            \"\"\"The wrapper function that actually executes the wrapped function within the spinner context.\n\n            Args:\n                *args: Positional arguments passed to the wrapped function.\n                **kwargs: Keyword arguments passed to the wrapped function.\n            \"\"\"\n            with st.spinner(text=text):\n                func(*args, **kwargs)\n\n        return wrapper_func\n\n    return _spinner\n\n\n@st.cache_data\ndef load_config():\n    \"\"\"Loads config.\"\"\"\n    return get_config()\n\n\nconf = load_config()\n\n\nclass RAGApp:\n    \"\"\"Application class to manage a Retrieval-Augmented Generation (RAG) model interface.\n\n    Attributes:\n        app: The main application or server instance hosting the RAG model.\n        conf: Configuration settings or parameters for the application.\n    \"\"\"\n\n    def __init__(self, app, conf):\n        \"\"\"Initializes the RAGApp with a given application and configuration.\n\n        Args:\n            app: The main application or framework instance that this class will interact with.\n            conf: A configuration object or dictionary containing settings for the application.\n        \"\"\"\n        self.app = app\n        self.conf = conf\n\n    def render_sidebar(self):\n        \"\"\"Renders the sidebar in the application interface with model selection and parameters.\"\"\"\n        with st.sidebar:\n            st.title(\"GRAG\")\n            st.subheader(\"Models and parameters\")\n            st.sidebar.selectbox(\n                \"Choose a model\",\n                [\n                    \"Llama-2-13b-chat\",\n                    \"Llama-2-7b-chat\",\n                    \"Mixtral-8x7B-Instruct-v0.1\",\n                    \"gemma-7b-it\",\n                ],\n                key=\"selected_model\",\n            )\n            st.sidebar.slider(\n                \"Temperature\",\n                min_value=0.1,\n                max_value=1.0,\n                value=0.1,\n                step=0.1,\n                key=\"temperature\",\n            )\n            st.sidebar.slider(\n                \"Top-k\", min_value=1, max_value=5, value=3, step=1, key=\"top_k\"\n            )\n            st.button(\"Load Model\", on_click=self.load_rag)\n            st.checkbox(\"Show sources\", key=\"show_sources\")\n\n    @spinner(text=\"Loading model...\")\n    def load_rag(self):\n        \"\"\"Loads the specified RAG model based on the user's selection and settings in the sidebar.\"\"\"\n        if \"rag\" in st.session_state:\n            del st.session_state[\"rag\"]\n\n        llm_kwargs = {\n            \"temperature\": st.session_state[\"temperature\"],\n        }\n        if st.session_state[\"selected_model\"] == \"Mixtral-8x7B-Instruct-v0.1\":\n            llm_kwargs[\"n_gpu_layers\"] = 16\n            llm_kwargs[\"quantization\"] = \"Q4_K_M\"\n        elif st.session_state[\"selected_model\"] == \"gemma-7b-it\":\n            llm_kwargs[\"n_gpu_layers\"] = 18\n            llm_kwargs[\"quantization\"] = \"f16\"\n\n        retriever_kwargs = {\n            \"client_kwargs\": {\n                \"read_only\": True,\n            },\n            \"top_k\": st.session_state[\"top_k\"],\n        }\n        client = DeepLakeClient(collection_name=\"usc\", read_only=True)\n        retriever = Retriever(vectordb=client)\n\n        st.session_state[\"rag\"] = BasicRAG(\n            model_name=st.session_state[\"selected_model\"],\n            stream=True,\n            llm_kwargs=llm_kwargs,\n            retriever=retriever,\n            retriever_kwargs=retriever_kwargs,\n        )\n        st.success(\n            f\"\"\"Model Loaded !!!\n    \n    Model Name: {st.session_state['selected_model']}\n    Temperature: {st.session_state['temperature']}\n    Top-k     : {st.session_state['top_k']}\"\"\"\n        )\n\n    def clear_cache(self):\n        \"\"\"Clears the cached data within the application.\"\"\"\n        st.cache_data.clear()\n\n    def render_main(self):\n        \"\"\"Renders the main chat interface for user interaction with the loaded RAG model.\"\"\"\n        st.title(\":us: US Constitution Expert! :mortar_board:\")\n        if \"rag\" not in st.session_state:\n            st.warning(\"You have not loaded any model\")\n        else:\n            user_input = st.chat_input(\"Ask me anything about the US Constitution.\")\n\n            if user_input:\n                with st.chat_message(\"user\"):\n                    st.write(user_input)\n                with st.chat_message(\"assistant\"):\n                    _ = st.write_stream(st.session_state[\"rag\"](user_input)[0])\n                    if st.session_state[\"show_sources\"]:\n                        retrieved_docs = st.session_state[\"rag\"].retriever.get_chunk(\n                            user_input\n                        )\n                        for index, doc in enumerate(retrieved_docs):\n                            with st.expander(f\"Source {index + 1}\"):\n                                st.markdown(\n                                    f\"**{index + 1}. {doc.metadata['source']}**\"\n                                )\n                                # if st.session_state['show_content']:\n                                st.text(f\"**{doc.page_content}**\")\n\n    def render(self):\n        \"\"\"Orchestrates the rendering of both main and sidebar components of the application.\"\"\"\n        self.render_main()\n        self.render_sidebar()\n\n\nif __name__ == \"__main__\":\n    app = RAGApp(st, conf)\n    app.render()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}