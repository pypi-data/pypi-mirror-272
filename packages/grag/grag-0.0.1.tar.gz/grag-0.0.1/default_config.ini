; This is the default config.ini file generated by GRAG
; All values are same as package defaults
; Values that do not have a default value are commented out

[llm]
;model_name : Llama-2-13b-chat
;quantization : Q5_K_M
;pipeline : llama_cpp
device_map : auto
task : text-generation
max_new_tokens : 1024
temperature : 0.1
n_batch : 1024
n_ctx : 6000
n_gpu_layers : -1
std_out : True
base_dir : ${root:root_path}/models

[chroma_client]
host : localhost
port : 8000
collection_name : grag
embedding_type : instructor-embedding
embedding_model : hkunlp/instructor-xl

[deeplake_client]
collection_name : grag
embedding_type : instructor-embedding
embedding_model : hkunlp/instructor-xl
store_path : ${data:data_path}/vectordb

[text_splitter]
chunk_size : 2000
chunk_overlap : 400

[multivec_retriever]
store_path : ${data:data_path}/doc_store
top_k : 3
id_key : doc_id
namespace : 71e4b558187b270922923569301f1039

[parse_pdf]
single_text_out : True
strategy : hi_res
infer_table_structure : True
extract_images : True
image_output_dir : None
add_captions_to_text : True
add_captions_to_blocks : True
table_as_html : False

[data]
data_path : ${root:root_path}/data

[env]
env_path : ${root:root_path}/.env

[root]
root_path : ~/Capstone_5
; check if ~ works

[quantize]
llama_cpp_path : ${root:root_path}
