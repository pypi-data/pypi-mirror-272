{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MNIST Data\n",
    "import hashlib\n",
    "import os\n",
    "import typing\n",
    "from urllib.error import HTTPError, URLError\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "def download_mnist() -> str:\n",
    "    \"\"\"Code to download mnist originates from keras/datasets:\n",
    "\n",
    "    https://github.com/keras-team/keras/blob/v2.15.0/keras/datasets/mnist.py#L25-L86\n",
    "    \"\"\"\n",
    "    origin_folder = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/\"\n",
    "    path = _get_file(\n",
    "        \"mnist.npz\",\n",
    "        origin=origin_folder + \"mnist.npz\",\n",
    "        file_hash=(\"731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1\"),\n",
    "    )\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "def _get_file(\n",
    "    fname: str,\n",
    "    origin: str,\n",
    "    file_hash: typing.Optional[str] = None,\n",
    "):\n",
    "    cache_dir = os.path.join(os.path.expanduser(\"~\"), \".keras\")\n",
    "    datadir_base = os.path.expanduser(cache_dir)\n",
    "    if not os.access(datadir_base, os.W_OK):\n",
    "        datadir_base = os.path.join(\"/tmp\", \".keras\")\n",
    "    datadir = os.path.join(datadir_base, \"datasets\")\n",
    "    os.makedirs(datadir, exist_ok=True)\n",
    "\n",
    "    fname = os.fspath(fname) if isinstance(fname, os.PathLike) else fname\n",
    "    fpath = os.path.join(datadir, fname)\n",
    "\n",
    "    download = False\n",
    "    if os.path.exists(fpath):\n",
    "        if file_hash is not None and not _validate_file(fpath, file_hash):\n",
    "            download = True\n",
    "    else:\n",
    "        download = True\n",
    "\n",
    "    if download:\n",
    "        try:\n",
    "            error_msg = \"URL fetch failure on {}: {} -- {}\"\n",
    "            try:\n",
    "                urlretrieve(origin, fpath)\n",
    "            except HTTPError as e:\n",
    "                raise Exception(error_msg.format(origin, e.code, e.msg)) from e\n",
    "            except URLError as e:\n",
    "                raise Exception(error_msg.format(origin, e.errno, e.reason)) from e\n",
    "        except (Exception, KeyboardInterrupt):\n",
    "            if os.path.exists(fpath):\n",
    "                os.remove(fpath)\n",
    "            raise\n",
    "\n",
    "        if (\n",
    "            os.path.exists(fpath)\n",
    "            and file_hash is not None\n",
    "            and not _validate_file(fpath, file_hash)\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Incomplete or corrupted file detected. \"\n",
    "                f\"The sha256 file hash does not match the provided value \"\n",
    "                f\"of {file_hash}.\",\n",
    "            )\n",
    "    return fpath\n",
    "\n",
    "\n",
    "def _validate_file(fpath, file_hash, chunk_size=65535):\n",
    "    hasher = hashlib.sha256()\n",
    "    with open(fpath, \"rb\") as fpath_file:\n",
    "        for chunk in iter(lambda: fpath_file.read(chunk_size), b\"\"):\n",
    "            hasher.update(chunk)\n",
    "\n",
    "    return str(hasher.hexdigest()) == str(file_hash)\n",
    "\n",
    "\n",
    "mnist_path = download_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "rng = np.random.default_rng(33)\n",
    "size = 25\n",
    "\n",
    "with np.load(mnist_path, allow_pickle=True) as fp:\n",
    "    test_images, labels = fp[\"x_train\"][:size], fp[\"y_train\"][:size]\n",
    "\n",
    "norm_test_imgs = np.repeat(test_images[:, np.newaxis, :, :], 3, axis=1) / 255\n",
    "jitter = rng.integers(10, size=norm_test_imgs.shape)\n",
    "norm_test_imgs += jitter\n",
    "\n",
    "\n",
    "rng.shuffle(test_images)\n",
    "rng.shuffle(norm_test_imgs)\n",
    "\n",
    "print(test_images.shape)\n",
    "print(norm_test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# All of these functions work on a single image assuming that channels is first\n",
    "# Assuming image is an ndarray\n",
    "\n",
    "\n",
    "def _slice_to_3_dimensions(array):\n",
    "    # Calculate how many dimensions need to be sliced\n",
    "    num_slices_needed = array.ndim - 3\n",
    "\n",
    "    # Generate a slicing tuple to keep the last three dimensions\n",
    "    # and take the first element of the rest\n",
    "    slice_tuple = (0,) * num_slices_needed + (slice(None),) * 3\n",
    "\n",
    "    # Apply the slicing tuple to the array\n",
    "    sliced_array = array[slice_tuple]\n",
    "\n",
    "    return sliced_array\n",
    "\n",
    "\n",
    "def _use_PIL(image):\n",
    "    adj_img = np.moveaxis(image, 0, -1)\n",
    "    print(adj_img.dtype)\n",
    "    im = Image.fromarray(np.moveaxis(image, 0, -1))\n",
    "    gray = im.convert(\"L\")\n",
    "    ed = gray.filter(ImageFilter.FIND_EDGES)\n",
    "    return np.array(ed)\n",
    "\n",
    "\n",
    "def _edge_filter(image):\n",
    "    offset = 0.5\n",
    "    kernel = np.ones((3, 3), np.uint8) * -1\n",
    "    kernel[1, 1] = 8\n",
    "    img = np.sum(image, axis=0).astype(np.float32)\n",
    "    edges = np.zeros_like(img, dtype=np.float32)\n",
    "\n",
    "    for y in range(1, img.shape[0] - 1):\n",
    "        for x in range(1, img.shape[1] - 1):\n",
    "            region = img[y - 1 : y + 2, x - 1 : x + 2]\n",
    "            edges[y, x] = np.sum(region * kernel) + offset\n",
    "\n",
    "    return edges.astype(np.uint8)\n",
    "\n",
    "\n",
    "class ImageStats:\n",
    "    def __init__(self, image: np.ndarray):\n",
    "        self.image = image\n",
    "        # Potentially need to add a check to make sure the image contains values\n",
    "        self.get_channels()\n",
    "        self.get_size_and_aspect_ratio()\n",
    "        self.get_image_bit()\n",
    "        self.get_missing_and_zero()\n",
    "        self.get_basic_stats_per_band()\n",
    "        self.get_histogram()\n",
    "        self.get_brightness()\n",
    "        self.get_blurriness()\n",
    "        self.get_entropy()\n",
    "        self.image = np.array([])\n",
    "\n",
    "    def get_channels(self):\n",
    "        dim = self.image.ndim\n",
    "        if dim == 2:\n",
    "            self.bands = 1\n",
    "            self.image = np.expand_dims(self.image, axis=0)\n",
    "        elif dim == 3:\n",
    "            self.bands = self.image.shape[0]\n",
    "        elif dim > 3:\n",
    "            print(\n",
    "                \"Image has more than 3 dimensions. \\\n",
    "                  This is for single images, not batches or videos. \\\n",
    "                  Selecting the first index in the beginning dimensions \\\n",
    "                  for continued processing.\"\n",
    "            )\n",
    "            self.bands = self.image.shape[-3]\n",
    "            self.image = _slice_to_3_dimensions(self.image)\n",
    "        else:\n",
    "            raise ValueError(\"You provided a 1-D array, not an image.\")\n",
    "\n",
    "    def get_size_and_aspect_ratio(self):\n",
    "        self.height = self.image.shape[-2]\n",
    "        self.width = self.image.shape[-1]\n",
    "\n",
    "        self.size = self.height * self.width\n",
    "        self.aspect_ratio = min(self.width / self.height, self.height / self.width)\n",
    "\n",
    "    def get_image_bit(self):\n",
    "        max_val = np.max(self.image)\n",
    "        min_val = np.min(self.image)\n",
    "\n",
    "        self.rescale = True\n",
    "        if min_val < 0:\n",
    "            self.bit_range = (min_val, max_val)\n",
    "        elif max_val <= 1:\n",
    "            self.bit_range = (0, 1)\n",
    "            self.rescale = False\n",
    "        elif max_val < 2**8:\n",
    "            self.bit_range = (0, 2**8 - 1)\n",
    "        elif max_val < 2**12:\n",
    "            self.bit_range = (0, 2**12 - 1)\n",
    "        elif max_val < 2**16:\n",
    "            self.bit_range = (0, 2**16 - 1)\n",
    "        else:\n",
    "            self.bit_range = (0, 2**32 - 1)\n",
    "\n",
    "    def get_missing_and_zero(self):\n",
    "        self.missing = np.sum(np.isnan(self.image))\n",
    "        self.zero = self.size - np.count_nonzero(self.image, axis=(1, 2))\n",
    "\n",
    "    def get_basic_stats_per_band(self):\n",
    "        self.mean = np.mean(self.image, axis=(1, 2))\n",
    "        self.var = np.var(self.image, axis=(1, 2))\n",
    "        self.skew = sp.stats.skew(self.image, axis=(1, 2))\n",
    "        self.kurtosis = sp.stats.kurtosis(self.image, axis=(1, 2))\n",
    "        # self.range = np.hstack([\n",
    "        #     np.min(self.image, axis=(1,2)).T,\n",
    "        #     np.max(self.image, axis=(1,2)).T\n",
    "        # ])\n",
    "        # self.median = np.median(self.image, axis=(1,2))\n",
    "        # Below code also implements the above range and median\n",
    "        self.percentiles = np.percentile(\n",
    "            self.image, q=[0, 25, 50, 75, 100], axis=(1, 2)\n",
    "        ).T  # this gives back array (bands, # of percentiles)\n",
    "        if self.bands == 1:\n",
    "            self.percentiles = self.percentiles[np.newaxis, :]\n",
    "\n",
    "    def get_histogram(self):\n",
    "        # Depending on max and min values this creates 256 bins of equal width\n",
    "        # Might need to consider normalizing first\n",
    "        # or determine how to define the range that works in all cases\n",
    "        self.histogram = np.vstack(\n",
    "            [\n",
    "                np.histogram(\n",
    "                    self.image[i, :, :],\n",
    "                    bins=256,\n",
    "                    range=self.bit_range,\n",
    "                )[0]\n",
    "                for i in range(self.bands)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def get_brightness(self):\n",
    "        luma = np.array([0.2126, 0.7152, 0.0722])\n",
    "        if self.rescale and self.bands == 3:\n",
    "            self.avg_brightness = np.sum(\n",
    "                luma * ((self.mean + self.bit_range[0]) / self.bit_range[1]) ** 2\n",
    "            )\n",
    "            adj_image = (self.image + self.bit_range[0]) / self.bit_range[1]\n",
    "            self.brightness = (\n",
    "                np.sum(luma[:, np.newaxis, np.newaxis] * adj_image**2) / self.size\n",
    "            )\n",
    "        elif self.rescale:\n",
    "            self.avg_brightness = np.mean(\n",
    "                (self.mean + self.bit_range[0]) / self.bit_range[1]\n",
    "            )\n",
    "            self.brightness = np.mean(\n",
    "                np.sum(\n",
    "                    (self.image + self.bit_range[0]) / self.bit_range[1], axis=(1, 2)\n",
    "                )\n",
    "                / self.size\n",
    "            )\n",
    "        elif self.bands == 3:\n",
    "            self.avg_brightness = np.repeat(np.sum(luma * self.mean**2), 3)\n",
    "            self.brightness = np.repeat(\n",
    "                np.sum(luma[:, np.newaxis, np.newaxis] * self.image**2) / self.size, 3\n",
    "            )\n",
    "        else:\n",
    "            self.avg_brightness = np.mean(self.mean)\n",
    "            self.brightness = np.mean(np.sum(self.image, axis=(1, 2)) / self.size)\n",
    "\n",
    "    def get_entropy(self):\n",
    "        flat_hist = np.sum(self.histogram, axis=0) / self.bands\n",
    "        flat_sum = flat_hist.sum()\n",
    "        if flat_sum == 0:\n",
    "            return 0\n",
    "\n",
    "        probabilities = flat_hist / flat_sum\n",
    "        probabilities = probabilities[probabilities > 0]\n",
    "\n",
    "        self.entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    def get_blurriness(self):\n",
    "        # if self.bands == 1 or self.bands == 3:\n",
    "        #     edges = _use_PIL(self.image)\n",
    "        # else:\n",
    "        edges = _edge_filter(self.image)\n",
    "\n",
    "        self.blurry = np.std(edges)\n",
    "\n",
    "\n",
    "class DatasetStats:\n",
    "    def __init__(\n",
    "        self,\n",
    "        images,\n",
    "        labels: Optional[np.ndarray] = None,\n",
    "        boxes: Optional[np.ndarray] = None,\n",
    "    ) -> None:\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.boxes = boxes\n",
    "\n",
    "        self.img_height = np.zeros(self.images.shape[0])\n",
    "        self.img_width = np.zeros(self.images.shape[0])\n",
    "        self.img_size = np.zeros(self.images.shape[0])\n",
    "        self.img_aspect_ratio = np.zeros(self.images.shape[0])\n",
    "        self.img_channels = np.zeros(self.images.shape[0])\n",
    "        self.img_missing = np.zeros(self.images.shape[0])\n",
    "        self.img_brightness = np.zeros(self.images.shape[0])\n",
    "        self.img_entropy = np.zeros(self.images.shape[0])\n",
    "        self.img_avg_brightness = np.zeros(self.images.shape[0])\n",
    "        self.img_blurriness = np.zeros(self.images.shape[0])\n",
    "        self.img_range = {}\n",
    "        self.image_stats = []\n",
    "\n",
    "        self.process_images()\n",
    "        self.process_channel_stats()\n",
    "        self.dataset_stats()\n",
    "\n",
    "    def process_images(self):\n",
    "        for i, image in enumerate(self.images):\n",
    "            stats = ImageStats(image)\n",
    "            self.image_stats.append(stats)\n",
    "\n",
    "            # These stats are per image so grabbing now\n",
    "            self.img_height[i] = stats.height\n",
    "            self.img_width[i] = stats.width\n",
    "            self.img_size[i] = stats.size\n",
    "            self.img_aspect_ratio[i] = stats.aspect_ratio\n",
    "            self.img_channels[i] = stats.bands\n",
    "            if stats.missing:\n",
    "                self.img_missing[i] = 1\n",
    "            if stats.bit_range not in self.img_range:\n",
    "                self.img_range[stats.bit_range] = 1\n",
    "            else:\n",
    "                self.img_range[stats.bit_range] += 1\n",
    "            self.img_avg_brightness[i] = stats.avg_brightness\n",
    "            self.img_brightness[i] = stats.brightness\n",
    "            self.img_entropy[i] = stats.entropy\n",
    "            self.img_blurriness[i] = stats.blurry\n",
    "\n",
    "    def process_channel_stats(self):\n",
    "        max_channels = int(self.img_channels.max())\n",
    "        # These stats are per channel\n",
    "        self.img_zeros = np.empty((self.images.shape[0], max_channels))\n",
    "        self.img_mean = np.empty((self.images.shape[0], max_channels))\n",
    "        self.img_var = np.empty((self.images.shape[0], max_channels))\n",
    "        self.img_skew = np.empty((self.images.shape[0], max_channels))\n",
    "        self.img_kurtosis = np.empty((self.images.shape[0], max_channels))\n",
    "        self.img_percentile = np.empty((self.images.shape[0], max_channels, 5))\n",
    "        self.img_histogram = np.empty((self.images.shape[0], max_channels, 256))\n",
    "\n",
    "        for i, stat in enumerate(self.image_stats):\n",
    "            if self.img_channels[i] < max_channels:\n",
    "                self.img_zeros[i, : self.img_channels[i]] = stat.zero\n",
    "                self.img_zeros[i, self.img_channels[i] :] = np.nan\n",
    "                self.img_mean[i, : self.img_channels[i]] = stat.mean\n",
    "                self.img_mean[i, self.img_channels[i] :] = np.nan\n",
    "                self.img_var[i, : self.img_channels[i]] = stat.var\n",
    "                self.img_var[i, self.img_channels[i] :] = np.nan\n",
    "                self.img_skew[i, : self.img_channels[i]] = stat.skew\n",
    "                self.img_skew[i, self.img_channels[i] :] = np.nan\n",
    "                self.img_kurtosis[i, : self.img_channels[i]] = stat.kurtosis\n",
    "                self.img_kurtosis[i, self.img_channels[i] :] = np.nan\n",
    "                self.img_percentile[i, : self.img_channels[i], :] = stat.percentiles\n",
    "                self.img_percentile[i, self.img_channels[i] :, :] = np.nan\n",
    "                self.img_histogram[i, : self.img_channels[i], :] = stat.histogram\n",
    "                self.img_histogram[i, self.img_channels[i] :, :] = np.nan\n",
    "            else:\n",
    "                self.img_zeros[i, :] = stat.zero\n",
    "                self.img_mean[i, :] = stat.mean\n",
    "                self.img_var[i, :] = stat.var\n",
    "                self.img_skew[i, :] = stat.skew\n",
    "                self.img_kurtosis[i, :] = stat.kurtosis\n",
    "                self.img_percentile[i, :, :] = stat.percentiles\n",
    "                self.img_histogram[i, :, :] = stat.histogram\n",
    "\n",
    "    def dataset_stats(self):\n",
    "        # These stats are listed in the form of (min, mean, max)\n",
    "        self.height = (\n",
    "            self.img_height.min(),\n",
    "            self.img_height.mean(),\n",
    "            self.img_height.max(),\n",
    "        )\n",
    "        self.width = (\n",
    "            self.img_width.min(),\n",
    "            self.img_width.mean(),\n",
    "            self.img_width.max(),\n",
    "        )\n",
    "        self.size = (\n",
    "            self.img_size.min(),\n",
    "            self.img_size.mean(),\n",
    "            self.img_size.max(),\n",
    "        )\n",
    "        self.aspect_ratio = (\n",
    "            self.img_aspect_ratio.min(),\n",
    "            self.img_aspect_ratio.mean(),\n",
    "            self.img_aspect_ratio.max(),\n",
    "        )\n",
    "        self.zeros = (\n",
    "            self.img_zeros.min(),\n",
    "            self.img_zeros.mean(),\n",
    "            self.img_zeros.max(),\n",
    "        )\n",
    "        self.avg_brightness = (\n",
    "            self.img_avg_brightness.min(),\n",
    "            self.img_avg_brightness.mean(),\n",
    "            self.img_avg_brightness.max(),\n",
    "        )\n",
    "        self.brightness = (\n",
    "            self.img_brightness.min(),\n",
    "            self.img_brightness.mean(),\n",
    "            self.img_brightness.max(),\n",
    "        )\n",
    "        self.entropy = (\n",
    "            self.img_entropy.min(),\n",
    "            self.img_entropy.mean(),\n",
    "            self.img_entropy.max(),\n",
    "        )\n",
    "        self.blurriness = (\n",
    "            self.img_blurriness.min(),\n",
    "            self.img_blurriness.mean(),\n",
    "            self.img_blurriness.max(),\n",
    "        )\n",
    "\n",
    "        # These stats are based on the dataset as a whole\n",
    "        if self.images.ndim == 3:\n",
    "            self.images = np.expand_dims(self.images, axis=1)\n",
    "        self.dataset_var = np.var(self.images, axis=(1, 2, 3))\n",
    "        self.dataset_skew = sp.stats.skew(self.images)\n",
    "        self.dataset_kurtosis = sp.stats.kurtosis(self.images)\n",
    "\n",
    "        # These stats give counts\n",
    "        self.missing = np.sum(self.img_missing)\n",
    "        self.value_range = self.img_range\n",
    "\n",
    "        # These stats give a tuple of (min/channel, mean/channel, max/channel)\n",
    "        # for example 3 channels would give ([1,2,3], [2,3,4], [3,4,5])\n",
    "        self.mean = (\n",
    "            np.nanmin(self.img_mean, axis=0),\n",
    "            np.nanmean(self.img_mean, axis=0),\n",
    "            np.nanmax(self.img_mean, axis=0),\n",
    "        )\n",
    "        self.var = (\n",
    "            np.nanmin(self.img_var, axis=0),\n",
    "            np.nanmean(self.img_var, axis=0),\n",
    "            np.nanmax(self.img_var, axis=0),\n",
    "        )\n",
    "        self.skew = (\n",
    "            np.nanmin(self.img_skew, axis=0),\n",
    "            np.nanmean(self.img_skew, axis=0),\n",
    "            np.nanmax(self.img_skew, axis=0),\n",
    "        )\n",
    "        self.kurtosis = (\n",
    "            np.nanmin(self.img_kurtosis, axis=0),\n",
    "            np.nanmean(self.img_kurtosis, axis=0),\n",
    "            np.nanmax(self.img_kurtosis, axis=0),\n",
    "        )\n",
    "        self.percentile = (\n",
    "            np.nanmin(self.img_percentile, axis=0),\n",
    "            np.nanmean(self.img_percentile, axis=0),\n",
    "            np.nanmax(self.img_percentile, axis=0),\n",
    "        )\n",
    "        self.histogram = (\n",
    "            np.nanmin(self.img_histogram, axis=0),\n",
    "            np.nanmean(self.img_histogram, axis=0),\n",
    "            np.nanmax(self.img_histogram, axis=0),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing single channel images - unnormalized\n",
    "single_channel = DatasetStats(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing multiple channel images - normalized\n",
    "multi_channel = DatasetStats(norm_test_imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
