{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Demonstration of lazy load and proxy objects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import our packages first\nIt is often nice to have units so we will also\nimport quantities\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import urllib\nimport neo\nimport quantities as pq\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's get a file\nNeuralEnsemble maintains a wide variety of small test\ndatasets that are free to use. We can use urllib to pull\ndown one of these files for use\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url_repo = \"https://web.gin.g-node.org/NeuralEnsemble/ephy_testing_data/raw/master/\"\n# Get med file\ndistantfile = url_repo + \"micromed/File_micromed_1.TRC\"\nlocalfile = \"./File_micromed_1.TRC\"\nurllib.request.urlretrieve(distantfile, localfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "create a reader\ncreating a reader for neo is easy it just requires using\nthe name of the desired reader and providing either a filename\nor a directory name (reader dependent). Since we got a micromed\nfile we will use MicromedIO.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reader = neo.MicromedIO(filename=\"File_micromed_1.TRC\")\nreader.parse_header()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "as always we can look view some interesting information about the\nmetadata and structure of a file just by printing the reader and\nit's header\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(reader)\nprint(f\"Header information: {reader.header}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's make a function that we want to apply to\nlook at lazy vs eager uses of the API\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def apply_my_fancy_average(sig_list):\n    \"\"\"basic average along triggers and then channels\n    here we go back to numpy with magnitude\n    to be able to use np.stack.\n\n    Because neo uses quantities to keep track of units\n    we can always get just the magnitude of an array\n    with `.magnitude`\n    \"\"\"\n    sig_list = [s.magnitude for s in sig_list]\n    sigs = np.stack(sig_list, axis=0)\n    return np.mean(np.mean(sigs, axis=0), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's set our limits for both cases. We will\nuse quantities to include time dimensions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lim_start = -20 * pq.ms  # 20 milliseconds before\nlim_end = +20 * pq.ms  # 20 milliseconds after"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start with eager (where `lazy=False`.) Everything\nis loaded into memory. We will read a segment of data.\nThis includes analog signal data and events data\n(final contents of a segment are dependent on the\nunderlying IO being used)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seg = reader.read_segment(lazy=False)\ntriggers = seg.events[0]\nanasig = seg.analogsignals[0]  # here anasig contain the whole recording in memory\nall_sig_chunks = []\nfor t in triggers.times:\n    t0, t1 = (t + lim_start), (t + lim_end)\n    anasig_chunk = anasig.time_slice(t0, t1)\n    all_sig_chunks.append(anasig_chunk)\n\n# After pulling all data into memory and then iterating through triggers\n# we end by doing our average\nm1 = apply_my_fancy_average(all_sig_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we do `lazy=True`, i.e. we do lazy loading. We\nonly load the data that we want into memory\nand we use a proxy object for our analogsignal until we\nload it chunk by chunk (no running out of memory!)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seg = reader.read_segment(lazy=True)\ntriggers = seg.events[0].load(time_slice=None)  # this load all triggers in memory\nanasigproxy = seg.analogsignals[0]  # this is a proxy\nall_sig_chunks = []\nfor t in triggers.times:\n    t0, t1 = (t + lim_start), (t + lim_end)\n    # at this step we load actual data into memory, but notice that we only load one\n    # chunk of data at a time, so we reduce the memory strain\n    anasig_chunk = anasigproxy.load(time_slice=(t0, t1))  # here real data are loaded\n    all_sig_chunks.append(anasig_chunk)\n\n# Finally we apply the same average as we did above\nm2 = apply_my_fancy_average(all_sig_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that either way the result is the same, but\nwe do not exhaust our RAM/memory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Eagerly loading data and averaging: {m1}\")\nprint(f\"Lazy loading data and average {m2}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}